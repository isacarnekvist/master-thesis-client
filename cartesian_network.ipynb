{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from theano import sandbox\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ddpg import Actor, Critic\n",
    "from naf.priority_buffer import PriorityBuffer\n",
    "from environment import Environment, WIN, LOSE, NEUTRAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_DIST = 0.01\n",
    "sandbox.cuda.use('gpu0')\n",
    "env = Environment(MAX_DIST, 'reaching-fixed-goal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "critic = Critic(env.get_state().shape[1], 2)\n",
    "critic_target = Critic(env.get_state().shape[1], 2)\n",
    "critic_target.clone_params(critic)\n",
    "\n",
    "actor = Actor(env.get_state().shape[1], 2, critic, output_scaling=MAX_DIST)\n",
    "actor_target = Actor(env.get_state().shape[1], 2, critic_target, output_scaling=MAX_DIST)\n",
    "actor_target.clone_params(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def return_average(env, actor, gamma=0.98):\n",
    "    rewards = []\n",
    "    for trial in range(32):\n",
    "        np.random.seed(trial)\n",
    "        env.reset()\n",
    "        n_steps = 256\n",
    "        return_ = 0.0\n",
    "        for i in range(n_steps):\n",
    "            mu = actor.predict(env.get_state())\n",
    "            _, r, _ = env.interact(*mu.flatten())\n",
    "            return_ += gamma ** i * r\n",
    "        rewards.append(return_)\n",
    "    return np.mean(rewards), np.std(rewards)\n",
    "\n",
    "return_average(env, actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_q(actor, critic, env):\n",
    "    xs = np.linspace(env.min_x, env.max_x, 12)\n",
    "    ys = np.linspace(env.min_y, env.max_y, 12)\n",
    "    xss, yss = np.meshgrid(xs, ys)\n",
    "    zss = np.zeros(xss.shape)\n",
    "    X = env.get_state()\n",
    "    for i, x in enumerate(xs):\n",
    "        for j, y in enumerate(ys):\n",
    "            zss[len(ys) - j - 1, i] = critic.predict(\n",
    "                X,\n",
    "                np.array([[x, y]])\n",
    "            )[0, 0]\n",
    "    plt.imshow(zss, cmap='inferno', interpolation='gaussian', aspect='auto',\n",
    "               extent=[-env.max_dist, env.max_dist, -env.max_dist, env.max_dist])\n",
    "\n",
    "    \n",
    "    plt.plot(0.0, 0.0, 'ko', markersize=10)\n",
    "    plt.plot(0.0, 0.0, 'w+', markersize=10)\n",
    "    \n",
    "    mu = actor.predict(env.get_state())\n",
    "    dx, dy = mu[0, :]\n",
    "    plt.plot(dx, dy, 'ko', markersize=10)\n",
    "    plt.plot(dx, dy, 'wo', markersize=8)\n",
    "    \n",
    "    d = np.array([env.goal_x - env.eef_x, env.goal_y - env.eef_y])\n",
    "    d /= np.linalg.norm(d)\n",
    "    plt.arrow(0.003 * d[0], 0.003 * d[1], 0.003 * d[0], 0.003 * d[1], width=0.0003, facecolor='w')\n",
    "    \n",
    "    plt.xticks(np.linspace(-0.01, 0.01, 5))\n",
    "    plt.yticks(np.linspace(0.01, -0.01, 5))\n",
    "    plt.colorbar().set_label('$Q(\\mathbf{x, u})$')\n",
    "\n",
    "\n",
    "def plot_pi(nn, env):\n",
    "    for x in np.linspace(env.min_x, env.max_x, 20):\n",
    "        for y in np.linspace(env.min_y, env.max_y, 20):\n",
    "            env.eef_x = x\n",
    "            env.eef_y = y\n",
    "            dx, dy = nn.predict(env.get_state())[0, :]\n",
    "            plt.arrow(x, y, dx, dy)\n",
    "    if env.mode.startswith('pushing'):\n",
    "        plt.plot(env.circle.x, env.circle.y, 'ko', markersize=10)\n",
    "        plt.plot(env.circle.x, env.circle.y, 'ro', markersize=8)\n",
    "    plt.plot(env.goal_x, env.goal_y, 'ko', markersize=10)\n",
    "    plt.plot(env.goal_x, env.goal_y, 'wo', markersize=8)\n",
    "    plt.title('$\\mathbf{\\mu(x)}$')\n",
    "    plt.xlim(env.min_x, env.max_x)\n",
    "    plt.ylim(env.min_y, env.max_y)\n",
    "    \n",
    "def plot_v(actor, critic, env):\n",
    "    xs = np.linspace(env.min_x, env.max_x, 12)\n",
    "    ys = np.linspace(env.min_y, env.max_y, 12)\n",
    "    xss, yss = np.meshgrid(xs, ys)\n",
    "    zss = np.zeros(xss.shape)\n",
    "    for i, x in enumerate(xs):\n",
    "        for j, y in enumerate(ys):\n",
    "            env.eef_x = x\n",
    "            env.eef_y = y\n",
    "            zss[len(ys) - j - 1, i] = critic.predict(\n",
    "                env.get_state(),\n",
    "                actor.predict(\n",
    "                    env.get_state()\n",
    "                )\n",
    "            )[0, 0]\n",
    "    plt.imshow(zss, cmap='inferno', interpolation='gaussian', aspect='auto',\n",
    "               extent=[env.min_x, env.max_x, env.min_y, env.max_y])\n",
    "    plt.plot(env.goal_x, env.goal_y, 'ko', markersize=10)\n",
    "    plt.plot(env.goal_x, env.goal_y, 'wo', markersize=8)\n",
    "    if env.mode.startswith('pushing'):\n",
    "        plt.plot(env.circle.x, env.circle.y, 'ko', markersize=10)\n",
    "        plt.plot(env.circle.x, env.circle.y, 'ro', markersize=8)\n",
    "    plt.xticks(np.linspace(env.min_x, env.max_x, 5))\n",
    "    plt.yticks(np.linspace(env.min_y, env.max_y, 5))\n",
    "    plt.colorbar().set_label('$V(\\mathbf{x})$')\n",
    "\n",
    "\n",
    "def plot_shebang(actor, critic, actor_target, critic_target, env):\n",
    "    env.reset()\n",
    "    plt.figure(figsize=(13, 9))\n",
    "    plt.subplot(321)\n",
    "    plot_pi(actor, env)\n",
    "    plt.subplot(322)\n",
    "    plt.title('V')\n",
    "    plot_v(actor, critic, env)\n",
    "    plt.subplot(323)\n",
    "    plot_pi(actor_target, env)\n",
    "    plt.subplot(324)\n",
    "    plt.title('V\\'')\n",
    "    plot_v(actor_target, critic_target, env)\n",
    "    plt.subplot(325)\n",
    "    env.reset()\n",
    "    plot_q(actor, critic, env)\n",
    "    plt.subplot(326)\n",
    "    plot_q(actor_target, critic_target, env)\n",
    "    plt.show()\n",
    "    \n",
    "plot_shebang(actor, critic, actor_target, critic_target, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_transition(env, priority_buffer):\n",
    "    x1 = env.get_state()\n",
    "    mu_rnd = MAX_DIST * np.tanh(75 * MAX_DIST * np.random.randn(2))\n",
    "    mu_act = actor.predict(x1)[0, :]\n",
    "    k = np.random.rand()\n",
    "    mu = k * mu_rnd + (1 - k) * mu_act\n",
    "    end_state, reward, x2 = env.interact(*mu)\n",
    "    priority_buffer.add({\n",
    "        'x1': x1[0, :],\n",
    "        'x2': x2[0, :],\n",
    "        'reward': reward,\n",
    "        'mu': mu,\n",
    "        'end_state': end_state\n",
    "    }).set_value(10.0)\n",
    "    if end_state in [WIN, LOSE]:\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "priority_buffer = PriorityBuffer(2 ** 20)\n",
    "\n",
    "for i in range(64):\n",
    "    env.reset()\n",
    "    sample_transition(env, priority_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_batch(X, Xp, Y, U, R, S, critic, actor_target, critic_target, priority_buffer, gamma=0.00):\n",
    "    nodes = []\n",
    "    for i in range(X.shape[0]):\n",
    "        sample = priority_buffer.sample()\n",
    "        nodes.append(sample)\n",
    "        X[i, :] = sample.data['x1']\n",
    "        Xp[i, :] = sample.data['x2']\n",
    "        U[i, :] = sample.data['mu']\n",
    "        R[i, :] = sample.data['reward']\n",
    "        S[i, :] = sample.data['end_state']\n",
    "    Y[:, :] = R + gamma * critic_target.predict(Xp, actor_target.predict(Xp))\n",
    "    [node.set_value(abs(e[0]) + 1e-6) for node, e in zip(nodes, critic.predict(X, U) - Y)]\n",
    "    Y[S == WIN] = R[S == WIN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_iterations = 2500000\n",
    "batch_size = 64\n",
    "\n",
    "X = np.zeros((batch_size, env.get_state().shape[1]))\n",
    "Xp = np.zeros((batch_size, env.get_state().shape[1]))\n",
    "U = np.zeros((batch_size, 2))\n",
    "Y = np.zeros((batch_size, 1))\n",
    "R = np.zeros((batch_size, 1))\n",
    "S = np.zeros((batch_size, 1))\n",
    "\n",
    "iteration = 0\n",
    "for iteration in range(iteration, n_iterations):\n",
    "    sample_transition(env, priority_buffer)\n",
    "    sample_batch(X, Xp, Y, U, R, S, critic, actor_target, critic_target, priority_buffer)\n",
    "    critic.fit(X, U, Y)\n",
    "    actor.fit(X)\n",
    "    critic_target.soft_update(critic)\n",
    "    actor_target.soft_update(actor)\n",
    "    if iteration % 512 == 0:\n",
    "        print(priority_buffer)\n",
    "        plot_shebang(actor, critic, actor_target, critic_target, env)\n",
    "        actor.save_params('actor_params.txt')\n",
    "        actor_target.save_params('actor_target_params.txt')\n",
    "        critic.save_params('critic_params.txt')\n",
    "        critic_target.save_params('critic_target_params.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "x = theano.shared(np.random.randn(2, 3))\n",
    "print(x.get_value())\n",
    "y = \n",
    "print(y.get_value())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
